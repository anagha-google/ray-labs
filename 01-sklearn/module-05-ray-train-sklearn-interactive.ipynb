{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module 5: Penguin Species Prediction: Interactive Distributed Scikit-Learn with Ray on Vertex AI"
      ],
      "metadata": {
        "id": "QMngEVZs2zt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This lab module is a primer on distributed sklearn with a model training sample - predicting penguin species - the same experiment we did in module 1, but on Ray.\n",
        "\n",
        "Ray documentation: https://docs.ray.io/en/latest/ray-more-libs/joblib.html"
      ],
      "metadata": {
        "id": "iT5R4_h8UG1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [1] Adjust Ray version in Colab versus Ray cluster as needed"
      ],
      "metadata": {
        "id": "_0rcx82rYGWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensure the ray version in Colab and the Ray on Vertex AI cluster are consistent\n",
        "#Uncomment, install, restart session and comment out the pip install\n",
        "#!pip install ray==2.4.0"
      ],
      "metadata": {
        "id": "UvLn8TtLTpxt",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711634027945,
          "user_tz": 300,
          "elapsed": 191,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer,make_column_transformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix,confusion_matrix,classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform.preview import vertex_ray\n",
        "import ray\n",
        "from ray.runtime_env import RuntimeEnv\n",
        "from ray.air.config import RunConfig\n",
        "from ray.air import CheckpointConfig, ScalingConfig\n",
        "from ray.util.joblib import register_ray\n"
      ],
      "metadata": {
        "id": "XNGcXZjMHR3H",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711633907985,
          "user_tz": 300,
          "elapsed": 138,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare, initialize\n",
        "project_id_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "PROJECT_ID = project_id_output[0]\n",
        "project_nbr_output = !gcloud projects describe $PROJECT_ID --format='value(projectNumber)'\n",
        "PROJECT_NBR = project_nbr_output[0]\n",
        "REGION=\"us-central1\"\n",
        "\n",
        "aiplatform.init(project='ray-of-sunshine', location='us-central1')\n",
        "RAY_ADDRESS=f\"vertex_ray://projects/{PROJECT_NBR}/locations/us-central1/persistentResources/ray-kicking-tires\""
      ],
      "metadata": {
        "id": "CQRpmJJBvop7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711633912194,
          "user_tz": 300,
          "elapsed": 2278,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [2] Train the model"
      ],
      "metadata": {
        "id": "oYiwmEXEYOuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distributing sklearn with Ray is as simple as putting all code that needs parallelizing under \"with joblib.parallel_backend('ray'):\" as shown below."
      ],
      "metadata": {
        "id": "-_ZTJxSsVRAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib, sys\n",
        "sys.modules['sklearn.externals.joblib'] = joblib\n",
        "from ray.util.joblib import register_ray\n",
        "register_ray()\n",
        "\n",
        "RUNTIME_ENV = {\n",
        "  \"pip\": [\n",
        "      \"google-cloud-aiplatform[ray]==1.40.0\",\n",
        "      \"ray[data]==2.4.0\",\n",
        "      \"ray[train]==2.4.0\",\n",
        "      \"ray[tune]==2.4.0\",\n",
        "      \"scikit-learn==1.2.2\",\n",
        "      \"google-cloud-bigquery\",\n",
        "      \"google-cloud-aiplatform\",\n",
        "      \"joblib\",\n",
        "      \"pandas<2.0.0\"\n",
        "  ],\n",
        "}\n",
        "ray.shutdown()\n",
        "ray.init(address=RAY_ADDRESS,runtime_env=RUNTIME_ENV)\n",
        "\n",
        "# The below statement will parallelize all code placed below it\n",
        "with joblib.parallel_backend('ray'):\n",
        "\n",
        "  # Column listing\n",
        "  numerical_columns_list=[\"culmen_length_mm\",\"culmen_depth_mm\",\"flipper_length_mm\",\"body_mass_g\"]\n",
        "  categorical_columns_list=[\"island\", \"sex\"]\n",
        "\n",
        "  # Read training data from BigQuery\n",
        "  client = bigquery.Client()\n",
        "  source_df = client.query(\"SELECT * FROM `ray_lab_ds.penguins_curated`\").to_dataframe()\n",
        "\n",
        "  # Features\n",
        "  X = source_df.drop(columns = ['species'])\n",
        "\n",
        "  # Label\n",
        "  Y = source_df['species']\n",
        "\n",
        "  # Split into train and test data\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 123)\n",
        "\n",
        "  # Preprocessing of numerical data\n",
        "  numerical_transformer = SimpleImputer(strategy='mean')\n",
        "  numerical_scaler = MinMaxScaler()\n",
        "\n",
        "  # Preprocessing for categorical data\n",
        "  categorical_preprocessing_pipe = Pipeline(steps=[\n",
        "      ('cat_col_imputer', SimpleImputer(strategy='most_frequent')),\n",
        "      ('cat_col_onehotencoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  # Bundle preprocessing for numerical imputer and categorical preprocessing pipeline\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "          ('num_col_imputer', numerical_transformer, numerical_columns_list),\n",
        "          ('cat_col_preprocessor', categorical_preprocessing_pipe, categorical_columns_list)\n",
        "      ])\n",
        "\n",
        "  random_forest_model = RandomForestClassifier(n_estimators=10)\n",
        "\n",
        "  # Bundle preprocessing and modeling code in a pipeline\n",
        "  penguin_training_pipeline = Pipeline(steps=[\n",
        "      ('preprocessor', preprocessor),\n",
        "      ('scaler', numerical_scaler),\n",
        "      ('model', random_forest_model)])\n",
        "\n",
        "  penguin_training_pipeline.fit(X_train, Y_train)\n",
        "\n",
        "  # Testing\n",
        "  penguin_predictions = penguin_training_pipeline.predict(X_test)\n",
        "  penguin_predictions\n",
        "\n",
        "  print('Accuracy : ', accuracy_score(Y_test, penguin_predictions))\n",
        "  print('F1 Score : ', f1_score(Y_test, penguin_predictions, average = 'weighted'))\n",
        "  print('Precision : ', precision_score(Y_test, penguin_predictions , average = 'weighted'))\n",
        "  print('Recall : ', recall_score(Y_test, penguin_predictions, average = 'weighted'))"
      ],
      "metadata": {
        "id": "EAunzkutuZH0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711633953640,
          "user_tz": 300,
          "elapsed": 41295,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af5445c-56a7-418b-fe18-0dcaecc77f98"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ray on Vertex AI]: Cluster State = State.RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-03-28 13:51:58,054\tWARNING pool.py:588 -- The 'context' argument is not supported using ray. Please refer to the documentation for how to control ray initialization.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.9767441860465116\n",
            "F1 Score :  0.9767112125372681\n",
            "Precision :  0.9777777777777777\n",
            "Recall :  0.9767441860465116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visit the Ray dashboard for your cluster and browse the logs. Note the logging nuances between interactive submission and job submission from a logging point of view. In the next module, we will submit the same experiment to the Ray job API."
      ],
      "metadata": {
        "id": "BPQxVt28WLzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This concludes the lab module. Proceed to the [next module](https://github.com/anagha-google/ray-labs/blob/main/01-sklearn/module-06-ray-train-sklearn-job-api-README.md)."
      ],
      "metadata": {
        "id": "Oq8KL8AcWI7B"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "name": "module-05-ray-train-sklearn-interactive.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}